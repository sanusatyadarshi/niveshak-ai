api:
  alpha_vantage:
    api_key: ${ALPHA_VANTAGE_API_KEY}
  anthropic:
    api_key: ${ANTHROPIC_API_KEY}
    model: claude-3-sonnet-20240229
  financial_modeling_prep:
    api_key: ${FMP_API_KEY}
  ollama:
    base_url: http://localhost:11434
    max_tokens: 200
    model: deepseek-r1:7b
    temperature: 0.1
  openai:
    api_key: ${OPENAI_API_KEY}
    max_tokens: 2000
    model: gpt-4.1-nano
    temperature: 0.1
app:
  environment: development
  name: NiveshakAI
  version: 0.1.0
cache:
  enabled: true
  max_size_mb: 1000
  ttl_hours: 24
embedding:
  base_url: http://localhost:11434
  batch_size: 50
  chunk_overlap: 100
  chunk_size: 500
  model: nomic-embed-text
  provider: ollama
llm:
  fallback_provider: openai
  provider: ollama
  # PDF Analysis LLM Configuration
  pdf_analysis:
    provider: openai # Default to OpenAI for PDF analysis (openai, anthropic, ollama)
    model: gpt-4.1-nano # Will use the model from the selected provider's config
    temperature: 0.1 # Lower temperature for more consistent extraction
logging:
  backup_count: 5
  file: logs/niveshak.log
  level: INFO
  max_file_size: 10MB
processing:
  max_file_size_mb: 50
  max_workers: 4
  parallel_processing: true
  supported_formats:
    - pdf
    - txt
    - docx
storage:
  books_dir: data/books
  cache_dir: .cache
  embeddings_dir: data/embeddings
  reports_dir: data/reports
vector_db:
  provider: qdrant
  qdrant:
    collection_name: niveshak_knowledge
    host: localhost
    port: 6333
    vector_size: 768
    timeout: 300
  weaviate:
    class_name: NiveshakDocument
    url: http://localhost:8080
